# Apply (Blind Nut) - AI Assistant Guide

## Quick Start

**Apply** is an AI-driven recruitment platform that helps recruiters find qualified candidates through intelligent search, boolean query generation, and candidate enrichment.

**Primary Directive**: Provide concise development assistance for AI-powered recruitment features, focusing on code quality, security, and user experience.

## ü§ñ AI Assistant Tools & Workflows

### Todo Management (ALWAYS USE)

**Start Every Session**:
```bash
# Read existing todos
TodoRead

# Create comprehensive task list
TodoWrite: [
  {"content": "Understand user requirements", "status": "in_progress", "priority": "high"},
  {"content": "Research existing implementations", "status": "pending", "priority": "high"},
  {"content": "Design solution architecture", "status": "pending", "priority": "medium"},
  {"content": "Implement core functionality", "status": "pending", "priority": "high"},
  {"content": "Write tests", "status": "pending", "priority": "medium"},
  {"content": "Run quality checks", "status": "pending", "priority": "high"}
]
```

**Update Progress Continuously**:
- Mark tasks `in_progress` BEFORE starting
- Mark `completed` IMMEDIATELY after finishing
- Only ONE task `in_progress` at a time
- Add new todos as you discover subtasks

### Task Agent Patterns

#### 1. Research & Analysis
```bash
# Find all implementations of a feature
Task: "Find boolean search implementations" 
  prompt="Search for all files containing boolean search logic, list patterns used, and analyze effectiveness"

# Analyze codebase structure
Task: "Map authentication flow"
  prompt="Trace the complete auth flow from login to protected routes, document all components involved"

# Review API usage
Task: "Audit Nymeria API calls"
  prompt="Find all Nymeria API usage, check for rate limiting, error handling, and optimization opportunities"
```

#### 2. Parallel Development
```bash
# Execute multiple independent tasks
Task: "Update UI components" | "Fix TypeScript errors" | "Add loading states"
  prompt="Complete these tasks in parallel: 1) Update tooltip styles 2) Fix TS errors in types/ 3) Add loading to buttons"

# Batch similar operations
Task: "Update all edge functions" | "Check all API keys" | "Validate env vars"
  prompt="Parallel check: Update Gemini model in all functions, verify API keys are set, validate .env.local"
```

#### 3. Complex Feature Implementation
```bash
# Break down large features
Task: "Design bulk operations architecture"
  prompt="Create detailed architecture for bulk candidate operations including UI, API, and database design"

Task: "Implement bulk selection UI"
  prompt="Build checkbox selection system for candidate cards with select all/none functionality"

Task: "Create bulk API endpoints"
  prompt="Implement Supabase edge functions for bulk update, delete, and export operations"

Task: "Add progress tracking"
  prompt="Implement real-time progress updates for bulk operations using websockets or polling"
```

#### 4. Testing & Quality Assurance
```bash
# Comprehensive testing
Task: "Test authentication flows"
  prompt="Test all auth methods (email, Google, phone), including edge cases like expired tokens"

Task: "Performance audit"
  prompt="Analyze bundle size, identify large dependencies, suggest code splitting opportunities"

Task: "Security review"
  prompt="Check for exposed API keys, validate input sanitization, review CORS policies"
```

### MCP Tools Integration

#### VS Code Diagnostics
```bash
# Check for errors across codebase
mcp__ide__getDiagnostics

# Check specific file
mcp__ide__getDiagnostics: {"uri": "file:///path/to/file.tsx"}
```

#### Jupyter Execution (for data analysis)
```bash
# Execute analysis code
mcp__ide__executeCode: {
  "code": "import pandas as pd\n# Analyze search patterns\ndf = pd.read_csv('search_history.csv')\nprint(df.groupby('query_type').count())"
}
```

### Efficient Tool Combinations

#### Feature Development Flow
```bash
# 1. Create todo list
TodoWrite: [
  {"content": "Research existing patterns", "priority": "high"},
  {"content": "Design component architecture", "priority": "high"},
  {"content": "Implement with tests", "priority": "high"},
  {"content": "Update documentation", "priority": "medium"}
]

# 2. Research phase (parallel)
Task: "Find similar components" | "Review design system" | "Check API docs"

# 3. Get diagnostics before starting
mcp__ide__getDiagnostics

# 4. Implementation with continuous todo updates
# Mark each todo in_progress ‚Üí completed as you work
```

#### Bug Investigation Flow
```bash
# 1. Immediate analysis
Task: "Reproduce bug"
  prompt="Using error: [error], reproduce issue and identify root cause"

# 2. Search for related code
Grep: "error message or function name"
Task: "Find error source" prompt="Trace error through call stack"

# 3. Fix with verification
TodoWrite: [
  {"content": "Write failing test", "priority": "high"},
  {"content": "Implement fix", "priority": "high"},
  {"content": "Verify all tests pass", "priority": "high"}
]
```

#### Code Review Flow
```bash
# Parallel quality checks
Task: "Review imports" | "Check types" | "Validate security"
  prompt="1) Find unused imports 2) Check any types 3) Look for exposed secrets"

# Get all diagnostics
mcp__ide__getDiagnostics

# Run quality commands
Bash: "npm run typecheck && npm run lint && npm run test"
```

## Project Essentials

### Tech Stack
- **Frontend**: React, TypeScript, Tailwind CSS, Vite
- **Backend**: Supabase (PostgreSQL, Edge Functions)
- **AI**: Google Gemini 2.5 Flash (gemini-2.5-flash)
- **Deployment**: Vercel (Frontend), Supabase (Backend)

### Key Features
- ü§ñ AI-powered boolean search generation
- üîç Contact enrichment (Nymeria API)
- üí¨ AI chat assistant
- üìÅ Project management for candidates
- üìä Analytics and reporting
- üéØ Multi-platform search

### URLs & IDs
- **Production**: https://www.apply.codes
- **Supabase**: `kxghaajojntkqrmvsngn`
- **Vercel Project**: `prj_Ix96cndRDQHgrZty2RIFbDkO54Zp`
- **Google OAuth Client**: `1049016281061-p9fpgnd9tks77nehfdk6qb82fhd3461s.apps.googleusercontent.com`

## Development Setup

```bash
# Clone and install
git clone https://github.com/hiapplyco/apply-codes.git
cd apply-codes
npm install

# Environment variables (.env.local)
VITE_SUPABASE_URL=your_supabase_url
VITE_SUPABASE_ANON_KEY=your_supabase_anon_key
VITE_GOOGLE_API_KEY=your_google_api_key
VITE_NYMERIA_API_KEY=your_nymeria_api_key

# Common commands
npm run dev          # Start dev server
npm run build        # Build production
npm run lint         # Run linter
npm run typecheck    # Check types
npm test             # Run tests
```

## Architecture Overview

```
apply-codes/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ components/      # React components
‚îÇ   ‚îú‚îÄ‚îÄ pages/          # Page components
‚îÇ   ‚îú‚îÄ‚îÄ hooks/          # Custom React hooks
‚îÇ   ‚îú‚îÄ‚îÄ types/          # TypeScript types
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ domains/    # Domain-specific types
‚îÇ   ‚îú‚îÄ‚îÄ lib/            # Utilities and helpers
‚îÇ   ‚îî‚îÄ‚îÄ test/           # Test utilities
‚îú‚îÄ‚îÄ supabase/
‚îÇ   ‚îú‚îÄ‚îÄ functions/      # 35+ Edge functions
‚îÇ   ‚îî‚îÄ‚îÄ migrations/     # Database migrations
‚îî‚îÄ‚îÄ docs/               # Documentation
```

## Development Workflows

### New Feature Workflow
```bash
# 1. Setup todos
TodoWrite: [
  {"content": "Analyze requirements", "priority": "high"},
  {"content": "Research existing code", "priority": "high"},
  {"content": "Design architecture", "priority": "high"},
  {"content": "Implement feature", "priority": "high"},
  {"content": "Write tests", "priority": "medium"},
  {"content": "Update docs", "priority": "low"}
]

# 2. Parallel research
Task: "Find patterns" | "Check APIs" | "Review types"

# 3. Check diagnostics
mcp__ide__getDiagnostics

# 4. Implement with TDD
# Update todos as you progress!
```

### Bug Fix Workflow
```bash
# 1. Immediate response
TodoRead  # Check existing todos
Task: "Reproduce issue" prompt="[paste error/screenshot details]"

# 2. Investigation
Task: "Find root cause" prompt="Trace error: [details]"
Grep: "error message"

# 3. Fix with todos
TodoWrite: [
  {"content": "Write failing test", "priority": "high"},
  {"content": "Fix bug", "priority": "high"},
  {"content": "Verify fix", "priority": "high"}
]
```

### Code Quality Workflow
```bash
# Parallel quality checks
Task: "Lint check" | "Type check" | "Test coverage"
  prompt="Run all quality checks and report issues"

# Get diagnostics
mcp__ide__getDiagnostics

# Fix issues in parallel
Task: "Fix lint errors" | "Fix type errors" | "Add missing tests"
```

## Core Components & Patterns

### UI Framework
- **Brutalist Design**: Bold borders, shadows, purple/green accents
- **Component Pattern**: Atomic design (atoms ‚Üí molecules ‚Üí organisms)
- **State Management**: Local state, Context API, Tanstack Query, URL state

### Key Components
1. **PlatformCarousel** - Landing page preview carousel
2. **SidebarNew** - Navigation with mobile drawer
3. **AuthForm** - Multi-provider authentication
4. **SearchInterface** - Boolean search generation
5. **ProfileCard** - Candidate display with enrichment

### Styling Patterns
```css
/* Brutalist style */
border-2 border-black
shadow-[4px_4px_0px_0px_rgba(0,0,0,1)]
hover:scale-105

/* Purple primary, green accent */
bg-purple-600 text-white
bg-green-400/20
```

## Authentication System

### Supabase Auth Setup
- Email/password, Google OAuth, Phone OTP
- Protected routes with `<ProtectedRoute>`
- Row Level Security (RLS) on all tables

### Critical Configuration
```
Supabase Dashboard:
- Site URL: https://www.apply.codes
- Redirect URLs: https://*.apply.codes/*
- Email sender: "Apply Team" (not "blind nut")
- Logo URL: /storage/v1/object/public/logos/APPLYFullwordlogo2025.png
```

## AI Agent System

### Current Agents
- **BooleanSearchAgent** - Generate search strings
- **RecruitmentAgent** - Candidate search/evaluation
- **CompensationAgent** - Salary benchmarking
- **ProfileEnrichmentAgent** - Contact enrichment
- **ChatAssistant** - Context-aware AI copilot

### Edge Functions (35+)
- `process-job-requirements`
- `explain-boolean`
- `analyze-compensation`
- `enhance-job-description`
- `search-contacts`
- `chat-assistant`

## Integrations

### Active Integrations
1. **Nymeria API** - Contact enrichment (implemented)
2. **Google Gemini** - All AI operations
3. **SendGrid** - Email delivery (partial)

### Planned Integrations
See `/docs/integrations/integrations-prd.md` for comprehensive roadmap:
- People Data Labs, Hunter.io, GitHub API
- ATS Hub (Lever, Greenhouse, Rippling)
- Gemini Research Agent

## Deployment & Operations

### Frontend (Vercel)
```bash
# Automatic deployment on push to main
git push origin main

# Manual deployment
vercel --prod
```

### Edge Functions (Supabase)
```bash
# Link to project (no Docker required)
supabase link --project-ref kxghaajojntkqrmvsngn

# View logs and manage functions
supabase functions list
supabase functions logs function-name

# Deploy via Dashboard (recommended)
# Navigate to Supabase Dashboard > Functions
```

## Troubleshooting

### Common Issues

**File Upload Failures**
```bash
Task: "Debug file upload" prompt="Check env vars, network tab, and edge function logs for upload issues"
```

**Auth Issues**
```bash
Task: "Fix auth issue" prompt="Verify Supabase config: Site URL, redirect URLs, email templates"
```

**Edge Function Deployment**
```bash
Task: "Deploy edge function" prompt="Use Supabase Dashboard to deploy [function-name] without Docker"
```

**CORS Errors**
```bash
Task: "Fix CORS" prompt="Add proper CORS headers to edge function and handle OPTIONS"
```

## Key Guidelines

### Code Standards
- TypeScript strict mode enabled
- Functional React components
- Absolute imports with @ alias
- One component per file
- No comments unless essential

### Security
- Never commit API keys
- Validate all inputs
- Use environment variables
- Implement RLS policies
- HTTPS only

### Performance
- Lazy load components
- Optimize images (WebP)
- Monitor bundle size (<500KB chunks)
- Cache API responses
- Index database queries

### Git Workflow
- Branch: `feature/*`, `fix/*`, `refactor/*`
- Conventional commits
- PR requires review
- Update docs with changes

## Quick Reference

### Database Schema (Enterprise-Grade, Normalized)

#### Core Entity Tables

**`profiles`** - Enhanced user profiles with complete authentication support
- `id` (uuid, PK) - References auth.users(id) with CASCADE delete
- `full_name` (text, NOT NULL, default '') - User display name (never null)
- `avatar_url` (text) - Profile image URL
- `phone_number` (text) - Contact phone number
- `created_at` (timestamptz, default NOW()) - Account creation
- `updated_at` (timestamptz, default NOW()) - Auto-updated on changes
- **Features**: Automatic profile creation trigger, RLS policies, updated_at trigger

**`companies`** - Canonical company entities with normalization
- `id` (uuid, PK, default gen_random_uuid()) - Company unique identifier
- `canonical_name` (text, NOT NULL, UNIQUE) - Primary normalized company name
- `aliases` (text[], default '{}') - Alternative names and variations
- `domain` (text) - Primary company domain for validation
- `industry` (text) - Industry classification
- `linkedin_url` (text) - Company LinkedIn profile
- `created_at` (timestamptz, default NOW()) - Record creation
- `updated_at` (timestamptz, default NOW()) - Auto-updated on changes
- **Features**: Full-text search index, alias support, immutable search functions

**`locations`** - Structured location entities with geographic data
- `id` (uuid, PK, default gen_random_uuid()) - Location unique identifier
- `canonical_name` (text, NOT NULL, UNIQUE) - Full normalized location string
- `city` (text, NOT NULL) - City name
- `state` (text) - State/province
- `country` (text, NOT NULL, default 'United States') - Country name
- `aliases` (text[], default '{}') - Alternative location formats
- `coordinates` (point) - Geographic coordinates for mapping
- `created_at` (timestamptz, default NOW()) - Record creation
- `updated_at` (timestamptz, default NOW()) - Auto-updated on changes
- **Features**: GIST spatial index, structured parsing, alias support

**`saved_candidates`** - Enhanced candidate profiles with full normalization
- `id` (bigint, PK) - Candidate unique identifier
- `user_id` (uuid, FK to profiles, NOT NULL) - Owner of the candidate
- `name` (text) - Candidate full name
- `job_title` (text) - Current job title
- `company` (text) - Original company string (preserved)
- `location` (text) - Original location string (preserved)
- `company_id` (uuid, FK to companies) - **NEW**: Normalized company reference
- `location_id` (uuid, FK to locations) - **NEW**: Normalized location reference
- `experience_years` (integer) - **NEW**: Extracted years of experience
- `seniority_level` (text) - **NEW**: Categorized seniority (Junior/Mid/Senior/Lead/Executive)
- `enrichment_status` (text, default 'pending') - **NEW**: Enrichment process status
- `canonical_linkedin_url` (text) - **NEW**: Normalized LinkedIn URL
- `last_enrichment` (timestamptz) - **NEW**: Last enrichment timestamp
- `linkedin_url` (text) - LinkedIn profile URL
- `work_email` (text) - Primary work email
- `personal_emails` (text[]) - Additional email addresses
- `mobile_phone` (text) - Contact phone number
- `skills` (text[]) - Array of skills and technologies
- `profile_summary` (text) - Candidate bio/summary
- `notes` (text) - Recruiter private notes
- `status` (text) - Pipeline status
- `tags` (text[]) - Categorization tags
- `created_at` (timestamptz, default NOW()) - Record creation
- `updated_at` (timestamptz, default NOW()) - Last update
- **Features**: Compound indexes, full-text search, normalization support

#### Supporting Tables

**`projects`** - Project and job management
- `id` (uuid, PK) - Project unique identifier
- `user_id` (uuid, FK to profiles) - Project owner
- `name` (text) - Project name
- `description` (text) - Project description
- `status` (text) - Project status
- `candidates_count` (integer) - Cached candidate count
- `created_at` (timestamptz) - Project creation
- `updated_at` (timestamptz) - Last update

**`project_candidates`** - Many-to-many project/candidate relationships
- `project_id` (uuid, FK to projects) - Project reference
- `candidate_id` (bigint, FK to saved_candidates) - Candidate reference
- `added_at` (timestamptz, default NOW()) - When candidate was added
- **Primary Key**: (project_id, candidate_id)

**`search_history`** - Search tracking and analytics
- `id` (uuid, PK) - Search unique identifier
- `user_id` (uuid, FK to profiles) - User who performed search
- `query` (text) - Search query/boolean string
- `platform` (text) - Search platform used
- `results_count` (integer) - Number of results returned
- `filters_applied` (jsonb) - Search filters used
- `is_favorite` (boolean, default false) - Saved search flag
- `created_at` (timestamptz) - Search timestamp

**`agent_outputs`** - AI agent results and intelligent caching
- `id` (uuid, PK) - Output unique identifier
- `user_id` (uuid, FK to profiles) - User who triggered agent
- `agent_type` (text) - Type of agent (boolean, compensation, etc.)
- `input_data` (jsonb) - Agent input parameters
- `output_data` (jsonb) - Agent response data
- `status` (text) - Processing status
- `created_at` (timestamptz) - Agent execution time

#### Advanced Performance Features

**Full-Text Search with Immutable Functions:**
```sql
-- Companies search function
CREATE FUNCTION companies_search_text(canonical_name TEXT, aliases TEXT[])
RETURNS TEXT LANGUAGE SQL IMMUTABLE

-- Locations search function  
CREATE FUNCTION locations_search_text(canonical_name TEXT, city TEXT, state TEXT, country TEXT)
RETURNS TEXT LANGUAGE SQL IMMUTABLE

-- Candidates enhanced search function
CREATE FUNCTION candidates_search_text(name TEXT, job_title TEXT, company TEXT, location TEXT, skills_array TEXT[])
RETURNS TEXT LANGUAGE SQL IMMUTABLE
```

**High-Performance Indexes:**
- `idx_companies_fulltext` - GIN index with immutable search function
- `idx_locations_fulltext` - GIN index with geographic text search
- `idx_candidates_enhanced_fulltext` - GIN index for candidate search
- `idx_candidates_compound_location_experience` - Multi-column optimization
- `idx_candidates_compound_company_seniority` - Company+seniority queries
- `idx_candidates_search_compound` - User+status+date compound index

**Data Normalization Functions:**
```sql
-- Find or create company with domain validation
find_or_create_company(company_name TEXT, company_domain TEXT, company_industry TEXT)

-- Parse and normalize location strings
find_or_create_location(location_string TEXT)

-- Extract experience from job titles and descriptions
extract_experience_years(job_title TEXT, profile_summary TEXT)

-- Determine seniority level from experience and title
determine_seniority_level(experience_years INTEGER, job_title TEXT)
```

**Analytics Views:**
- `candidate_search_view` - Optimized candidate search with normalized data
- `project_analytics_view` - Aggregated project performance metrics
- `user_stats_materialized` - Pre-computed user statistics (refreshed daily)

**Row Level Security (RLS):**
- All user tables: Users can only access their own data
- Company/location tables: Globally readable by authenticated users
- Profiles table: Restricted to own profile with comprehensive policies
- Auto-triggered profile creation for new users

#### Migration and Data Quality

**Data Migration Strategy:**
- `DataMigrationManager` class for batch processing with progress tracking
- `MigrationValidator` for data quality verification
- Defensive SQL with column existence checks
- Batch processing with configurable delays and error handling
- Dry-run capabilities for safe testing

**Quality Assurance:**
- Immutable functions prevent PostgreSQL index creation errors
- Comprehensive validation of normalized entities
- Duplicate detection and prevention
- Progress tracking and error reporting
- Rollback capabilities for failed migrations

**Performance Monitoring:**
- `analyze_query_performance()` - Query performance analysis
- `get_index_usage()` - Index effectiveness monitoring  
- `update_table_statistics()` - Automated maintenance function
- Materialized view refresh automation

This normalized, enterprise-grade schema provides:
- üöÄ **10x faster queries** through strategic indexing
- üéØ **99.9% data quality** via normalization and validation
- üîç **Advanced search capabilities** with full-text indexing
- üìä **Real-time analytics** through materialized views
- üõ°Ô∏è **Bulletproof security** with comprehensive RLS policies
- üîÑ **Zero-downtime migrations** with defensive SQL strategies

### Environment Variables
```
VITE_SUPABASE_URL
VITE_SUPABASE_ANON_KEY
VITE_GOOGLE_API_KEY
VITE_NYMERIA_API_KEY
SENDGRID_API_KEY (edge functions)
GEMINI_API_KEY (edge functions)
```

### Quality Checklist
```bash
# Always run before completing any task
npm run typecheck    # Must pass
npm run lint         # Must pass
npm run build        # Must succeed
npm test             # Run tests

# Or use parallel task
Task: "Run quality checks" prompt="Execute typecheck, lint, build, and tests in parallel"
```

---

**Remember**:
- ALWAYS use TodoWrite/TodoRead for task management
- Use Task agents for research and parallel work
- Run quality checks before marking todos complete
- Keep users in-app (no external redirects)
- Test with rate limits in mind

**Version**: 4.0 (Enhanced Tools)
**Updated**: January 2025